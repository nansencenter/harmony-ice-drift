{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b607bd00",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "user = os.getenv('USER')\n",
    "import sys\n",
    "sys.path.insert(0, f'/Home/{user}/py/stereoid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "099e7c82",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import glob\n",
    "from multiprocessing import Pool\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pyproj\n",
    "\n",
    "import drama.utils as drtls\n",
    "from drama.io import cfg as cfg\n",
    "from drama.geo import SingleSwathBistatic\n",
    "\n",
    "import stereoid.sar_performance as strsarperf\n",
    "import stereoid.oceans.tools.observation_tools as obs_tools\n",
    "from stereoid.sea_ice import FwdModel, SceneGenerator, RetrievalModel\n",
    "\n",
    "from harmony23lib import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66b936fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run ID\n",
    "mode = \"IWS\"\n",
    "runid='2021_1_seaice'\n",
    "\n",
    "# stereoid path\n",
    "path=f'/data1/{user}/stereoid'\n",
    "pardir=path + '/PAR/'\n",
    "parfile=pardir + 'Hrmny_' + '2021_1_seaice' + '.cfg'\n",
    "cfgdata = cfg.ConfigFile(drtls.get_par_file(parfile))\n",
    "main_dir=path + ''\n",
    "\n",
    "# input neXtSIM files\n",
    "model_dir=path + '/nextsim/'\n",
    "\n",
    "# radar model\n",
    "#fstr_dual = strsarperf.sarperf_files(main_dir, rx_dual_name, mode=mode, runid=runid) # at the moment IW only I think\n",
    "fstr_ati = strsarperf.sarperf_files(main_dir, 'tud_2020_tripple_ati', mode=mode, runid=runid)\n",
    "fstr_s1 = strsarperf.sarperf_files(main_dir, 'sentinel', mode=mode, runid=runid, is_bistatic=False)\n",
    "\n",
    "# some additional settings\n",
    "x_res=cfgdata.sar.gr_res # is readily set \n",
    "y_res=cfgdata.sar.gr_res # make it equal to the monostatic ground-range resolution\n",
    "t_res=cfgdata.orbit.timestep # along-track time resolution of generated swath\n",
    "sp=[complex(1.6,0.07), 0.0030, 0.015, 0.04] \n",
    "ip=[complex(3.65,0.38), 0.0030, 0.015] \n",
    "pol='hh+hv'\n",
    "prod_res = np.sqrt(x_res * y_res)\n",
    "b_ati=10\n",
    "t_orb=12/175\n",
    "\n",
    "inc_m_deg=31.1\n",
    "inc_m = np.deg2rad(inc_m_deg)\n",
    "along_track_separation=375e3 # should be consistent with the PAR file\n",
    "obs_geo = obs_tools.build_geometry(parfile, inc_m, dau=along_track_separation)\n",
    "\n",
    "fwdm = FwdModel(parfile,sp,ip)# initialize forwaes model\n",
    "sgm = SceneGenerator(fwdm,x_res,y_res,n_orbs=2) # initialize scene generator\n",
    "proj = pyproj.proj.Proj('+proj=stere +lat_0=90 +lat_ts=75')\n",
    "n_days = 1\n",
    "n_orbits_per_day = 3\n",
    "n_orbits = n_days * n_orbits_per_day\n",
    "# output folder\n",
    "outpath=f'/data1/{user}/stereoid/RESULTS/SeaIce/SeaIceDrift'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dc0ec0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_input_dir(input_dir_mask):\n",
    "    \"\"\"\n",
    "    Process all files from one directory.\n",
    "\n",
    "    Inputs:\n",
    "        input_dir_mask : str, mask of files in one dir, e.g. '/data/experiment01/field_2020*npz'\n",
    "\n",
    "    Outputs are NPZ files. They contain velocities and coordinates and are stored in <outpath>\n",
    "    \n",
    "    \"\"\"\n",
    "    input_dir, mask = os.path.split(input_dir_mask)\n",
    "    root_input_dir, exp_dir = os.path.split(input_dir)\n",
    "    files = [os.path.basename(f) for f in sorted(glob.glob(f'{input_dir_mask}'))]\n",
    "    dates = [f.split('_')[1].split('Z')[0] for f in files]\n",
    "    dates = [datetime(int(d[0:4]), int(d[4:6]), int(d[6:8]), int(d[9:11])) for d in dates]\n",
    "    t_ns = np.array([(d - dates[0]).total_seconds()/24/60/60 for d in dates])\n",
    "\n",
    "    print(len(files), files[0], files[-1])\n",
    "    swb = SingleSwathBistatic(par_file=parfile, dau=along_track_separation, n_orbits=n_orbits)\n",
    "    for n_orbit in range(n_orbits):\n",
    "        t = n_orbit * t_orb\n",
    "        I = np.argmin(np.absolute(t-t_ns))\n",
    "        filename = files[I]\n",
    "        print(input_dir, n_orbit, filename, t, I)\n",
    "        try:\n",
    "            swth_bst = next(swb)\n",
    "            print(n_orbit, 'OK', swth_bst.master_swath.Northing.shape)\n",
    "        except:\n",
    "            print(n_orbit, 'Error creating orbit geometry')\n",
    "            continue\n",
    "        x_sz, y_sz, nor_sz = create_swath_grids(swth_bst, proj, t_res, y_res)\n",
    "        x, y, v_e, v_n, c, t = read_nextsim_data(f'{input_dir}/{filename}', proj)\n",
    "        v_e_sz, v_n_sz, landmask, icemask = interpolate_nextsim_on_swath(x, y, v_e, v_n, c, t, x_sz, y_sz)\n",
    "        u_int, v_int = compute_nextsim_uv(v_e_sz, v_n_sz, landmask, nor_sz)\n",
    "        dopp, s_dopp, r_dopp_r0 = get_doppler(sgm, obs_geo, u_int, v_int, x_res, pol, inc_m, fstr_s1, fstr_ati, prod_res, b_ati)\n",
    "        r_dopp_d0 = remove_texture_noise(r_dopp_r0, s_dopp)\n",
    "\n",
    "        # get indices of large land free, icy chuncks\n",
    "        ch_starts, ch_stops, ch_sizes = get_chunks(landmask, icemask)\n",
    "        # process chunk-by-chunk\n",
    "        for ch_i, (ch_start, ch_stop, ch_size) in enumerate(zip(ch_starts, ch_stops, ch_sizes)):\n",
    "            r_dopp_r = r_dopp_r0[ch_start:ch_stop]\n",
    "            r_dopp_a = np.zeros_like(r_dopp_r)\n",
    "            r_dopp_m = np.zeros_like(r_dopp_r)\n",
    "            for i in range(3):\n",
    "                r_dopp_m[:,:,i] = denoise_mk(dopp[ch_start:ch_stop,:,i], r_dopp_d0[ch_start:ch_stop,:,i])\n",
    "                r_dopp_a[:,:,i] = apply_anisotropic_diffusion(r_dopp_m[:,:,i], kappa=5)\n",
    "\n",
    "            retrievalm = RetrievalModel(obs_geo.concordia, obs_geo.discordia, parfile)\n",
    "            uv_r = retrievalm.sea_ice_drift(np.array(r_dopp_r)) # from raw Doppler data\n",
    "            uv_m = retrievalm.sea_ice_drift(np.array(r_dopp_m)) # from Doppler data filtered with texture denoising and MK filrer\n",
    "            uv_a = retrievalm.sea_ice_drift(np.array(r_dopp_a)) # from Doppler data filtered with texture denoising, MK and AD filter\n",
    "\n",
    "            ofile = f'{outpath}/pass_{exp_dir}_{filename[6:-4]}_{n_orbit:02}_{ch_i:02}.npz'\n",
    "            print(ofile)\n",
    "            np.savez(ofile, \n",
    "                     uv_i=np.dstack([u_int[ch_start:ch_stop], v_int[ch_start:ch_stop]]), # interpolated input\n",
    "                     uv_r=uv_r,\n",
    "                     uv_m=uv_m,\n",
    "                     uv_a=uv_a,\n",
    "                     x = x_sz[ch_start:ch_stop],\n",
    "                     y = y_sz[ch_start:ch_stop],\n",
    "                     n = nor_sz[ch_start:ch_stop],\n",
    "                    )\n",
    "\n",
    "def compute_defor(ifile, stp=2):\n",
    "    \"\"\" Compute deformation from using MK and AK methods.\n",
    "    \n",
    "    Inputs:\n",
    "        ifile : str, name of input file\n",
    "        stp :, int, zoomout factor\n",
    "    Outputs are stored in NPZ files and contain 3 types of deformation fields:\n",
    "        ???i - from original velocities\n",
    "        ???m - using MK method\n",
    "        ???a using AK method\n",
    "        \n",
    "        \"\"\"\n",
    "    ofile = ifile.replace('.npz', '_defor.npz')\n",
    "    ds = np.load(ifile)\n",
    "\n",
    "    ui = ds['uv_i'][:,:,0]\n",
    "    vi = ds['uv_i'][:,:,1]\n",
    "    divi, shei, toti = get_deformation(ui[::stp, ::stp], vi[::stp, ::stp])\n",
    "\n",
    "    um = ds['uv_m'][:,:,0]\n",
    "    vm = ds['uv_m'][:,:,1]\n",
    "    divm, shem, totm = get_deformaion_from_uv_mk2(um, vm, stp=stp)\n",
    "\n",
    "    ua = ds['uv_a'][:,:,0]\n",
    "    va = ds['uv_a'][:,:,1]\n",
    "    uz = multi_look(ua, stp)\n",
    "    vz = multi_look(va, stp)\n",
    "    uc, vc = clustering_filter(uz, vz, n_clusters=50, med_filt_size=5, xy_interpolation=True)\n",
    "    divc, shec, totc = get_deformation(uc, vc)\n",
    "    np.savez(ofile, divi=divi, shei=shei, toti=toti, divm=divm, shem=shem, totm=totm, divc=divc, shec=shec, totc=totc, stp=stp)\n",
    "\n",
    "def make_quiclook(ifile1, uv_names, df_names):\n",
    "    \"\"\"\n",
    "    Plot U/V and deformation on a PNG file. \n",
    "    \n",
    "    Inputs:\n",
    "        ifile1 : str, input file\n",
    "        uv_names : list of str, name of U/V variables in input file to visualise\n",
    "        df_names : list of str, name of deformation variables in input file to visualise\n",
    "    Outputs are saved as PNG files with the same name as input file but with PNG extension.\n",
    "    \n",
    "    \"\"\"\n",
    "    ifile2 = ifile1.replace('.npz', '_defor.npz')\n",
    "    ofile = ifile2.replace('_defor.npz', '_ql.png')\n",
    "\n",
    "    ds1 = np.load(ifile1)\n",
    "    ds2 = np.load(ifile2)\n",
    "\n",
    "    n_maps = len(uv_names + df_names)\n",
    "    fig, axs = plt.subplots(n_maps, 1, figsize=(10,2*n_maps))\n",
    "    i = 0\n",
    "\n",
    "    for uv_name in uv_names:\n",
    "        if uv_name in ds1.files:\n",
    "            u = ds1[uv_name][:,:,0]\n",
    "            axs[i].imshow(u.T, clim=[-0.1, 0.1], cmap='bwr')\n",
    "            axs[i].set_title(uv_name)\n",
    "            i += 1\n",
    "\n",
    "    for df_name in df_names:\n",
    "        if df_name in ds2.files:\n",
    "            d = ds2[df_name]\n",
    "            axs[i].imshow(d.T, clim=[0, 0.02], cmap='plasma_r')\n",
    "            axs[i].set_title(df_name)\n",
    "            i += 1\n",
    "\n",
    "    plt.savefig(ofile, dpi=100, bbox_inches='tight', pad_inches=0)\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adeef054",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute velocities in paralel\n",
    "input_dir_masks = [\n",
    "    f'/data1/{user}/stereoid/nextsim/original_data/field_20190101*00Z.npz',\n",
    "    f'/data1/{user}/stereoid/nextsim/newer_exp/field_20070105*00Z.npz',\n",
    "    f'/data1/{user}/stereoid/nextsim/sa05free_2019/field_20190101*00Z.npz',\n",
    "]\n",
    "\n",
    "with Pool(3) as p:\n",
    "    p.map(process_input_dir, input_dir_masks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "716690e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute deformations in paralel\n",
    "ifiles = []\n",
    "ifiles += sorted(glob.glob(f'/data1/{user}/stereoid/RESULTS/SeaIce/SeaIceDrift/pass_original_data*00Z_??_??.npz'))\n",
    "ifiles += sorted(glob.glob(f'/data1/{user}/stereoid/RESULTS/SeaIce/SeaIceDrift/pass_newer_exp*00Z_??_??.npz'))\n",
    "ifiles += sorted(glob.glob(f'/data1/{user}/stereoid/RESULTS/SeaIce/SeaIceDrift/pass_sa05free_2019*00Z_??_??.npz'))\n",
    "with Pool(10) as p:\n",
    "    p.map(compute_defor, ifiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30b06bee",
   "metadata": {},
   "outputs": [],
   "source": [
    "uv_names = ['uv_i', 'uv_m', 'uv_a']\n",
    "df_names = ['toti', 'totc']\n",
    "\n",
    "for ifile in ifiles:\n",
    "    make_quiclook(ifile, uv_names, df_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f17ee2af",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
